import pandas
import numpy
import plotly.express
import statsmodels.api
import statsmodels.formula.api
import patsy.contrasts
group = numpy.repeat(["A", "B", "C", "D"], repeats = 25)
group
mean = (3, 4, 4, 3)
sigma = (1.5, 1.5, 1.5, 1.5)
n = (25, 25, 25, 25)
# lists, library_name.function_name notation
group = numpy.repeat(["A", "B", "C", "D"], repeats = 25)
# tuples
mean = (3, 4, 4, 3)
sigma = (1.5, 1.5, 1.5, 1.5)
n = (25, 25, 25, 25)
# tuples
mean = (3, 4, 4, 3)
sigma = (1.5, 1.5, 1.5, 1.5)
n = (25, 25, 25, 25)
# iterate numpy.random.normal through 4 values for mean, sigma, and n, and then concatenate result into 1 array
x = numpy.concatenate([numpy.random.normal(mean, sigma, n) for mean, sigma, n in zip(mean, sigma, n)])
# y is corrletaed r = 0.75 with x, add random noise
y = x * 0.75 + numpy.random.normal(loc = 0.00, scale = 1.00, size = 100)
for  mean, sigma, n in zip(mean, sigma, n):
numpy.random.normal(mean, sigma, n)
for  mean, sigma, n in zip(mean, sigma, n)
numpy.random.normal(mean, sigma, n)
for  mean, sigma, n in zip(mean, sigma, n):
numpy.random.normal(mean, sigma, n)
numpy.random.normal(mean, sigma, n)]
zip(mean, sigma, n)
# tuples
mean = (3, 4, 4, 3)
sigma = (1.5, 1.5, 1.5, 1.5)
n = (25, 25, 25, 25)
numpy.random.normal(mean, sigma, n) for mean, sigma, n in zip(mean, sigma, n)
[numpy.random.normal(mean, sigma, n) for mean, sigma, n in zip(mean, sigma, n)]
numpy.random.normal(mean, sigma, n)]
[numpy.random.normal(mean, sigma, n)]
mean
sigma
n
for mean, sigma, n in zip(mean, sigma, n):
numpy.random.normal(mean, sigma, n)
zip(mean, sigma, n)
for mean, sigma, n in zip(mean, sigma, n)
for mean, sigma, n in zip(mean, sigma, n):
numpy.random.normal(mean, sigma, n)
for mean, sigma, n in zip(mean, sigma, n):
numpy.random.normal(mean, sigma, n)
numpy.random.normal(mean, sigma, n)
numpy.random.normal(mean, sigma, n)
for mean, sigma, n in zip(mean, sigma, n):
numpy.random.normal(mean, sigma, n)
for i in 0:5:
print(i)
for i in 0:5:
print(i)
for i in 0:5:
print(i)
0:5
[0:5]
for x in [0, 1, 2, 3, 4, 5]: print(i)
for x in [0, 1, 2, 3, 4, 5]: print(i)
for x in [0, 1, 2, 3, 4, 5]:
print(i)
[0, 1, 2, 3, 4, 5]
fruits = ["apple", "banana", "cherry"]
for x in fruits:
print(x)
fruits = (1, 2, 3, 4, 5)
for x in fruits:
print(x)
for mean, sigma, n in zip(mean, sigma, n):
numpy.random.normal(mean, sigma, n)
for mean in (3, 4, 4, 5):
numpy.random.normal(loc = mean, scale = 1.5, size = 25)
x = for mean in (3, 4, 4, 5):
numpy.random.normal(loc = mean, scale = 1.5, size = 25)
x * 0.75 + numpy.random.normal(loc = 0.00, scale = 1.00, size = 100)
for mean, sigma, n in zip(mean, sigma, n:
numpy.random.normal(loc = mean, scale = sigma, size = n)
x = for mean, sigma, n in zip(mean, sigma, n:
numpy.random.normal(loc = mean, scale = sigma, size = n)
x = for mean, sigma, n in zip(mean, sigma, n):
numpy.random.normal(loc = mean, scale = sigma, size = n)
x = for mean, sigma, n in zip(mean, sigma, n): numpy.random.normal(loc = mean, scale = sigma, size = n)
x = for (mean, sigma, n) in zip(mean, sigma, n):
numpy.random.normal(loc = mean, scale = sigma, size = n)
(mean, sigma, n)
for mu, s, i in zip(mean, sigma, n):
numpy.random.normal(loc = mu, scale = s, size = i)
for mu, s, i in zip(mean, sigma, n):
numpy.random.normal(loc = mu, scale = s, size = i)
for (mu, s, i) in zip(mean, sigma, n):
numpy.random.normal(loc = mu, scale = s, size = i)
numpy.random.normal(loc = mu, scale = s, size = i)
for mu, s, i in zip(mean, sigma, n):
numpy.random.normal(loc = mu, scale = s, size = i)
x = for mu, s, i in zip(mean, sigma, n):
numpy.random.normal(loc = mu, scale = s, size = i)
numpy.random.normal(loc = mu, scale = s, size = i)
x = for mu, s, i in zip(mean, sigma, n):
numpy.random.normal(loc = mu, scale = s, size = i)
x = numpy.concatenate([numpy.random.normal(mean, sigma, n) for mean, sigma, n in zip(mean, sigma, n)])
x = numpy.concatenate([numpy.random.normal(mean, sigma, n) for mean, sigma, n in zip(mean, sigma, n)])
# iterate numpy.random.normal through 4 values for mean, sigma, and n, and then concatenate result into 1 array
# for comes after function
x = numpy.concatenate([numpy.random.normal(mean, sigma, n) for mean, sigma, n in zip(mean, sigma, n)])
# tuples
mean = (3, 4, 4, 3)
sigma = (1.5, 1.5, 1.5, 1.5)
n = (25, 25, 25, 25)
# iterate numpy.random.normal through 4 values for mean, sigma, and n, and then concatenate result into 1 array
# for comes after function
x = numpy.concatenate([numpy.random.normal(mean, sigma, n) for mean, sigma, n in zip(mean, sigma, n)])
for (a, b, c) in zip(mean, sigma, n):
numpy.random.normal(a, b, c)
x = for (mean, sigma, n) in zip(mean, sigma, n):
numpy.random.normal(mean, sigma, n)
# tuples
mean = (3, 4, 4, 3)
sigma = (1.5, 1.5, 1.5, 1.5)
n = (25, 25, 25, 25)
x = for (m, s, i) in zip(mean, sigma, n):
numpy.random.normal(loc = m, scale = s, size = i)
# tuples
mean = (3, 4, 4, 3)
sigma = (1.5, 1.5, 1.5, 1.5)
n = (25, 25, 25, 25)
# iterate numpy.random.normal through 4 values for mean, sigma, and n, and then concatenate result into 1 array
# for comes after function
x = for (m, s, i) in zip(mean, sigma, n):
numpy.random.normal(loc = m, scale = s, size = i)
for (a, b, c) in zip(mean, sigma, n):
...       numpy.random.normal(a, b, c)
# tuples
mean = (3, 4, 4, 3)
sigma = (1.5, 1.5, 1.5, 1.5)
n = (25, 25, 25, 25)
for (a, b, c) in zip(mean, sigma, n):
numpy.random.normal(a, b, c)
x = for (m, s, i) in zip(mean, sigma, n):
numpy.random.normal(m, s, i)
# tuples
mean = (3, 4, 4, 3)
sigma = (1.5, 1.5, 1.5, 1.5)
n = (25, 25, 25, 25)
# iterate numpy.random.normal through 4 values for mean, sigma, and n, and then concatenate result into 1 array
# for comes after function
x = for (a, b, c) in zip(mean, sigma, n):
numpy.random.normal(a, b, c)
for (a, b, c) in zip(mean, sigma, n):
numpy.random.normal(a, b, c)
x = for (a, b, c) in zip(mean, sigma, n):
numpy.random.normal(a, b, c)
for (a, b, c) in zip(mean, sigma, n):
numpy.random.normal(a, b, c)
x = for (a, b, c) in zip(mean, sigma, n):
numpy.random.normal(a, b, c)
x = [for (a, b, c) in zip(mean, sigma, n):
numpy.random.normal(a, b, c)]
x = for (a, b, c) in zip(mean, sigma, n): numpy.random.normal(a, b, c)
for (a, b, c) in zip(mean, sigma, n): numpy.random.normal(a, b, c)
x = [for (a, b, c) in zip(mean, sigma, n): numpy.random.normal(a, b, c)]
# tuples
mean = (3, 4, 4, 3)
sigma = (1.5, 1.5, 1.5, 1.5)
n = (25, 25, 25, 25)
# iterate numpy.random.normal through 4 values for mean, sigma, and n, and then concatenate result into 1 array
# for comes after function
x = []
for (a, b, c) in zip(mean, sigma, n): x.append.numpy.random.normal(a, b, c)
# iterate numpy.random.normal through 4 values for mean, sigma, and n, and then concatenate result into 1 array
# for comes after function
x = []
for (a, b, c) in zip(mean, sigma, n): x.append(numpy.random.normal(a, b, c))
x
# y is corrletaed r = 0.75 with x, add random noise
y = x * 0.75 + numpy.random.normal(loc = 0.00, scale = 1.00, size = 100)
# iterate numpy.random.normal through 4 values for mean, sigma, and n, and then concatenate result into 1 array
# for comes after function
x = ()
for (a, b, c) in zip(mean, sigma, n): x.append(numpy.random.normal(a, b, c))
# iterate numpy.random.normal through 4 values for mean, sigma, and n, and then concatenate result into 1 array
# for comes after function
x = []
for (a, b, c) in zip(mean, sigma, n): x.append(numpy.random.normal(a, b, c))
numpy.hstack(x)
# iterate numpy.random.normal through 4 values for mean, sigma, and n, and then concatenate result into 1 array
# for comes after function
x = []
for (a, b, c) in zip(mean, sigma, n): x.append(numpy.random.normal(a, b, c))
x = numpy.hstack(x)
# y is corrletaed r = 0.75 with x, add random noise
y = x * 0.75 + numpy.random.normal(loc = 0.00, scale = 1.00, size = 100)
# Empty list
x = []
# Append list with random normal variables
for (a, b, c) in zip(mean, sigma, n):
x.append(numpy.random.normal(a, b, c))
#
x = numpy.concatenate(x)
# y is corrletaed r = 0.75 with x, add random noise
y = x * 0.75 + numpy.random.normal(loc = 0.00, scale = 1.00, size = 100)
x = []
# Append list with random normal variables
for (a, b, c) in zip(mean, sigma, n):
x.append(numpy.random.normal(a, b, c))
x
# y is corrletaed r = 0.75 with x, add random noise
y = x * 0.75 + numpy.random.normal(loc = 0.00, scale = 1.00, size = 100)
# Empty list
x = []
# Append list with random normal variables
for (a, b, c) in zip(mean, sigma, n):
x.append(numpy.random.normal(a, b, c))
# Join results
x = numpy.concatenate(x)
# y is corrletaed r = 0.75 with x, add random noise
y = x * 0.75 + numpy.random.normal(loc = 0.00, scale = 1.00, size = 100)
# curly brackets, colons
data1 = pandas.DataFrame({"y": y, "x": x, "group": group})
# Chunk 1
# install.packages("reticulate")
library(reticulate)
# Chunk 2
# py_install("pandas")
# py_install("numpy")
# py_install("plotly")
# py_install("statsmodels")
# py_install("patsy")
# Chunk 3
import pandas
import numpy
import plotly.express
import statsmodels.api
import statsmodels.formula.api
import patsy.contrasts
# Chunk 4
# lists, library_name.function_name notation
group = numpy.repeat(["A", "B", "C", "D"], repeats = 25)
# Chunk 5
# tuples
mean = (3, 4, 4, 3)
sigma = (1.5, 1.5, 1.5, 1.5)
n = (25, 25, 25, 25)
# Chunk 6
# Empty list
x = []
# Append list with random normal variables
for (a, b, c) in zip(mean, sigma, n):
x.append(numpy.random.normal(a, b, c))
# Join results
x = numpy.concatenate(x)
# Chunk 7
# y is corrletaed r = 0.75 with x, add random noise
y = x * 0.75 + numpy.random.normal(loc = 0.00, scale = 1.00, size = 100)
# curly brackets, colons
data1 = pandas.DataFrame({"y": y, "x": x, "group": group})
# Helmert contrasts
group_helmert = patsy.contrasts.Helmert().code_without_intercept(list(set(group)))
# 2 main effects and 1 interaction contrast
group_factorial = patsy.contrasts.ContrastMatrix([[-1, -1, 1], [-1, 1, -1], [1, -1, -1], [1, 1, 1]], ["Main Effect 1", "Main Effect 2", "Interaction"])
plotly.express.box(data1, x = "group", y = "y")
blogdown:::serve_site()
blogdown:::serve_site()
?rep
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
2.066164 + 0.154605 * qt(1 - 0.05 / 2, df = 49)
t.test(rnorm(50))
x <- rnorm(50)
mean(x) + (sd(x) / sqrt(length(x) - 1)) * qt(1 - 0.05 / 2, df = 49)
t.test(x)
mean(x) + (sd(x) / sqrt(length(x))) * qt(1 - 0.05 / 2, df = 49)
psych::describe(x)
sqrt(length(x)))
sqrt(length(x))
sd(x) / sqrt(length(x))
psych::describe(x)$se
?rnorm
?factor
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
library(tidyverse)
clipboard()
clipboard() %>% read_csv()
clipboard() %>% read_csv() %>% View()
primary_polls <- read_csv(file = clipboard())
primary_polls <- read_csv(file = clipboard())
primary_polls %>% group_by(race, candidate_name) %>% summarise(pct_estimate_mean = mean(pct_estimate), n = n_estimates)
primary_polls %>% group_by(race, candidate_name) %>% summarise(pct_estimate_mean = mean(pct_estimate), n_estimates = n())
primary_polls %>% group_by(race, state, candidate_name) %>% summarise(pct_estimate_mean = mean(pct_estimate), n_estimates = n())
primary_polls %>% group_by(race, state, candidate_name) %>% summarise(pct_estimate_mean = mean(pct_estimate), n_estimates = n()) %>% arrange(candidate_name)
primary_polls %>% group_by(race, state, candidate_name) %>% summarise(pct_estimate_mean = mean(pct_estimate), n_estimates = n()) %>% arrange(candidate_name) %>% print(n = 25)
primary_polls %>% filter(candidate_name == "Al Gore" & race == "1988D") %>% ggplot(mapping = aes(x = modeldate, y = pct_estimate)) + geom_point(size = 4)
primary_polls %>% filter(candidate_name == "Al Gore" & race == "1988D") %>% ggplot(mapping = aes(x = modeldate, y = pct_estimate)) + geom_point(size = 4) + facet_wrap(facets = ~ state)
primary_polls %>% filter(candidate_name == "Al Gore" & race == "1988D") %>% ggplot(mapping = aes(x = modeldate, y = pct_estimate)) + geom_point(size = 4, alpha = 0.40) + facet_wrap(facets = ~ state)
primary_polls %>% filter(candidate_name == "Al Gore" & race == "1988D") %>% ggplot(mapping = aes(x = modeldate, y = pct_estimate)) + geom_point(size = 4, alpha = 0.20) + facet_wrap(facets = ~ state)
primary_polls %>% filter(candidate_name == "Al Gore" & race == "1988D") %>% ggplot(mapping = aes(x = modeldate, y = pct_estimate)) + geom_point(alpha = 0.20) + facet_wrap(facets = ~ state)
primary_polls %>% mutate(model_month = lubridate::month(modeldate)) %>% group_by(race, state, model_month, candidate_name) %>% summarise(pct_estimate_mean = mean(pct_estimate), n_estimates = n())
primary_polls %>% mutate(model_month = lubridate::month(modeldate)) %>% group_by(race, state, model_month, candidate_name) %>% summarise(pct_estimate_mean = mean(pct_estimate), n_estimates = n()) %>% filter(state == "National")
library(lubridate)
primary_polls %>% mutate(model_month = months(month(modeldate))) %>% group_by(race, state, model_month, candidate_name) %>% summarise(pct_estimate_mean = mean(pct_estimate), n_estimates = n()) %>% filter(state == "National")
primary_polls %>% mutate(model_month = month(modeldate, label = TRUE)) %>% group_by(race, state, model_month, candidate_name) %>% summarise(pct_estimate_mean = mean(pct_estimate), n_estimates = n()) %>% filter(state == "National")
primary_polls %>% mutate(model_month = month(modeldate, label = TRUE)) %>% group_by(race, state, model_month, candidate_name) %>% summarise(pct_estimate_mean = mean(pct_estimate), n_estimates = n()) %>% filter(state == "National") %>% arrange(candidate_name)
primary_polls %>% mutate(model_month = month(modeldate, label = TRUE)) %>% group_by(race, state, model_month, candidate_name) %>% summarise(pct_estimate_mean = mean(pct_estimate), n_estimates = n()) %>% filter(state == "National") %>% ggplot(mapping = aes(x = model_month, y = pct_estimate_mean, color = candidate_name)) + facet_wrap(facets = ~ race)
primary_polls %>% mutate(model_month = month(modeldate, label = TRUE)) %>% group_by(race, state, model_month, candidate_name) %>% summarise(pct_estimate_mean = mean(pct_estimate), n_estimates = n()) %>% filter(state == "National") %>% ggplot(mapping = aes(x = model_month, y = pct_estimate_mean, color = candidate_name)) + geom_line() + facet_wrap(facets = ~ race)
primary_polls %>% mutate(model_month = month(modeldate, label = TRUE)) %>% group_by(race, state, model_month, candidate_name) %>% summarise(pct_estimate_mean = mean(pct_estimate), n_estimates = n()) %>% filter(state == "National") %>% ggplot(mapping = aes(x = model_month, y = pct_estimate_mean, color = candidate_name, group = 1)) + geom_line() + facet_wrap(facets = ~ race)
primary_polls %>% mutate(model_month = month(modeldate, label = TRUE)) %>% group_by(race, state, model_month, candidate_name) %>% summarise(pct_estimate_mean = mean(pct_estimate), n_estimates = n()) %>% filter(state == "National") %>% ggplot(mapping = aes(x = model_month, y = pct_estimate_mean, color = candidate_name, group = candidate_name)) + geom_line() + facet_wrap(facets = ~ race)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
Sys.Date()
Sys.time()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::stop_server()
blogdown:::serve_site()
blogdown:::stop_server()
blogdown:::serve_site()
blogdown:::stop_server()
blogdown:::serve_site()
install.packages("gitcreds")
library(gitcreds)
gitcreds_set()
blogdown:::serve_site()
install.packages(c("arm", "backports", "bayestestR", "BH", "blogdown", "bookdown", "brio", "brms", "broom", "bslib", "candisc", "car", "carData", "caret", "class", "cli", "coin", "colourpicker", "conflicted", "conquer", "cpp11", "crayon", "credentials", "crosstalk", "data.table", "datawizard", "DBI", "deldir", "desc", "DescTools", "devtools", "diffobj", "digest", "distributional", "downlit", "DT", "dtplyr", "e1071", "effects", "effectsize", "emmeans", "Exact", "fansi", "forecast", "foreign", "fs", "future", "generics", "gert", "ggdist", "git2r", "gld", "glmnet", "glue", "gmailr", "goftest", "gsl", "hardhat", "heplots", "Hmisc", "hms", "htmlTable", "httpuv", "igraph", "insight", "ipred", "ISOcodes", "ivreg", "jmvcore", "jsonlite", "keras", "knitr", "lattice", "lava", "lavaan", "libcoin", "lmtest", "lubridate", "magrittr", "manipulateWidget", "maps", "maptools", "MASS", "Matrix", "MBESS", "memoise", "mgcv", "mgcViz", "mice", "mime", "multcomp", "mvtnorm", "nlme", "nloptr", "nnet", "officer", "OpenMx", "openssl", "openxlsx", "optimx", "padr", "parallelly", "parameters", "party", "performance", "pillar", "pkgbuild", "pkgdown", "pkgload", "plotly", "plotrix", "posterior", "pROC", "proxyC", "psych", "qgam", "quanteda", "quantreg", "ragg", "raster", "rcmdcheck", "Rcpp", "RcppArmadillo", "RcppParallel", "readr", "recipes", "reghelper", "remotes", "reticulate", "rex", "rgl", "rio", "rjson", "rlang", "rootSolve", "roxygen2", "rpart", "rpf", "rsample", "rsconnect", "rstan", "rvest", "s2", "sem", "servr", "sessioninfo", "sf", "shiny", "shinyjs", "sjmisc", "slam", "sp", "spatial", "spatstat", "spatstat.core", "spatstat.data", "spatstat.geom", "spatstat.linnet", "spatstat.sparse", "spatstat.utils", "spData", "spdep", "stopwords", "stringi", "systemfonts", "tensorflow", "testthat", "textshaping", "tfautograph", "TH.data", "tibble", "tidybayes", "tidymodels", "tidyr", "tidytext", "timetk", "tinytex", "tseries", "TTR", "tzdb", "usethis", "uuid", "V8", "viridis", "vroom", "waldo", "withr", "wk", "workflows", "xfun", "xml2", "yaml", "yardstick"))
blogdown:::serve_site()
blogdown::hugo_version()
blogdown::update_hugo()
blogdown::install_hugo()
blogdown:::serve_site()
blogdown::config_Rprofile()
blogdown:::serve_site()
blogdown::config_Rprofile()
# REMEMBER to restart R after you modify and save this file!
# First, execute the global .Rprofile if it exists. You may configure blogdown
# options there, too, so they apply to any blogdown projects. Feel free to
# ignore this part if it sounds too complicated to you.
if (file.exists("~/.Rprofile")) {
base::sys.source("~/.Rprofile", envir = environment())
}
# Now set options to customize the behavior of blogdown for this project. Below
# are a few sample options; for more options, see
# https://bookdown.org/yihui/blogdown/global-options.html
options(
# to automatically serve the site on RStudio startup, set this option to TRUE
blogdown.serve_site.startup = FALSE,
# to disable knitting Rmd files on save, set this option to FALSE
blogdown.knit.on_save = TRUE,
# build .Rmd to .html (via Pandoc); to build to Markdown, set this option to 'markdown'
blogdown.method = 'html'
)
# fix Hugo version
options(blogdown.hugo.version = "0.92.1")
blogdown:::serve_site()
blogdown::check_site()
blogdown::build_site()
blogdown:::serve_site()
blogdown:::hugo_build()
